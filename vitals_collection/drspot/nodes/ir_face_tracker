#!/usr/bin/env python

# Copyright 2020 Boston Dynamics Inc.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np
import cv2
import insightface

import rospy
from sensor_msgs.msg import Image
from geometry_msgs.msg import PolygonStamped, Point32
from std_msgs.msg import Bool
from std_srvs.srv import SetBool, SetBoolResponse
from cv_bridge import CvBridge

from drspot.utils.tracking import ROITracker

ENABLE_TOPIC = 'ir_face_tracker_enable'

IMAGE_TOPIC = 'thermal_image_raw'
SCALED_IMAGE_TOPIC = 'debug_thermal_tracking_rescale'
DEBUG_IMAGE_TOPIC = 'debug_thermal_tracking'
EYE_REGION_TOPIC = 'skin_temp_roi'
MASK_REGION_TOPIC = 'mask_roi'
TRACKING_STATUS_TOPIC = 'ir_tracking_status'
MAX_DROPOUT_BEFORE_RESET_SEC = 1.0
MAX_TIME_SINCE_DETECTION_SEC = 2.5

FACE_DETECTION_LIKELIHOOD_THRESHOLD = 0.5
MIN_FACE_DIM_PIXELS = 10
FACE_DETECTION_SCALE = 0.7
CV_TRACKER_TYPE = 'CSRT'

FACE_DETECTION_INTENSITY_RANGE = 150.0
FACE_DETECTION_INTENSITY_OFFSET = (255.0 - FACE_DETECTION_INTENSITY_RANGE) / 2.0

EYE_HALF_HEIGHT_FRAC_OF_FACE = 1.0 / 4.0
EYE_HALF_WIDTH_FRAC_OF_FACE = 0.45

# Shift the mask ROI down from the detected landmarks.
MASK_HEIGHT_FRAC_OF_FACE_DOWN = 0.05
MASK_HALF_HEIGHT_FRAC_OF_FACE = 0.35
MASK_HALF_WIDTH_FRAC_OF_FACE = 0.35

ROS_THERMAL_IMAGE_BUFFER_SIZE = 640*480 * 2 * 3

class FaceDetectorTracker(object):
    def image_callback(self, data):
        if not self.enabled:
            return

        det_msg = Bool()
        det_msg.data = False
        t = data.header.stamp.to_sec()
        if self.tlast is None:
            self.tlast = t
            self.tracking_status_pub.publish(det_msg)
            return

        # Detect backward jumps in time in replay.
        if self.tlast > t:
            self.clear_msmt_state()
            self.tlast = t
            rospy.logwarn_throttle(1, '{}: Backward jump in time'.format(self.name))
            self.tracking_status_pub.publish(det_msg)
            return

        # Detect skips in data.
        if t - self.tlast > MAX_DROPOUT_BEFORE_RESET_SEC:
            rospy.logwarn_throttle(1, '{}: Dropped samples for {} sec'.format(self.name, t - self.tlast))
            self.clear_msmt_state()
            self.tlast = t
            self.tracking_status_pub.publish(det_msg)
            return

        self.tlast = t

        cv_image = self.bridge.imgmsg_to_cv2(data, desired_encoding='passthrough')
        imin = np.amin(cv_image)
        imax = np.amax(cv_image)
        irange = imax - imin
        if irange == 0:
            rospy.logwarn_throttle(1, '{}: Blank IR image'.format(self.name))
            self.tracking_status_pub.publish(det_msg)
            return
        cv_image = ((cv_image - imin) * FACE_DETECTION_INTENSITY_RANGE / irange
                    + FACE_DETECTION_INTENSITY_OFFSET).astype('uint8')

        msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='passthrough')
        msg.header = data.header
        self.scaled_image_pub.publish(msg)

        chan3image = cv2.cvtColor(cv_image, cv2.COLOR_GRAY2RGB)

        # If tracking is OK, track. Else, detect and configure tracker.
        bboxes = np.array([])
        landmarks = np.array([])
        fidx = 0
        self.eye_tracker.update(cv_image)
        self.mouth_tracker.update(cv_image)
        last_detection_ok = self.tlast_detection is not None and t - self.tlast_detection < MAX_TIME_SINCE_DETECTION_SEC
        if self.eye_tracker.ok and self.mouth_tracker.ok and last_detection_ok:
            eye = self.eye_tracker.bbox.reshape((2, 2))
            mouth = self.mouth_tracker.bbox.reshape((2, 2))
        else:
            if not self.eye_tracker.ok or not self.mouth_tracker.ok:
                rospy.logwarn_throttle(1, '{}: Lost tracking; running face detector'.format(self.name))
            else:
                rospy.loginfo_throttle(1, '{}: Time-triggered face detection'.format(self.name))
            self.mouth_tracker = ROITracker(CV_TRACKER_TYPE)
            self.eye_tracker = ROITracker(CV_TRACKER_TYPE)
            bboxes, landmarks = self.detector.detect(chan3image,
                                                     threshold=FACE_DETECTION_LIKELIHOOD_THRESHOLD,
                                                     scale=FACE_DETECTION_SCALE)

            if len(bboxes) == 0:
                self.tracking_status_pub.publish(det_msg)
                rospy.logwarn_throttle(1, '{}: no faces detected'.format(self.name))
                self.clear_msmt_state()
                return

            # TODO - If we select a specific face, re-order so that face is first (index 0).
            if len(bboxes) > 1:
                rospy.logwarn_throttle(1, '{}: {} faces detected; picking the first'.format(self.name, len(bboxes)))

            wface = bboxes[fidx][2] - bboxes[fidx][0]
            hface = bboxes[fidx][3] - bboxes[fidx][1]
            if (wface < MIN_FACE_DIM_PIXELS) or (hface < MIN_FACE_DIM_PIXELS):
                self.tracking_status_pub.publish(det_msg)
                rospy.logwarn_throttle(1, '{}: face too small'.format(self.name))
                self.clear_msmt_state()
                return

            det_msg.data = True
            self.tracking_status_pub.publish(det_msg)
            self.tlast_detection = t

            leye = landmarks[fidx][0]
            reye = landmarks[fidx][1]
            mideye = 0.5 * (np.array(leye) + np.array(reye))
            half_weye = max(abs(leye[0] - mideye[0]), wface * EYE_HALF_WIDTH_FRAC_OF_FACE)
            half_heye = max(abs(leye[1] - mideye[1]), hface * EYE_HALF_HEIGHT_FRAC_OF_FACE)
            eye = mideye + np.array([[-half_weye, -half_heye], [half_weye, half_heye]])
            self.eye_tracker.start_track(cv_image, eye.reshape((4)))

            lmouth = landmarks[fidx][3]
            rmouth = landmarks[fidx][4]
            midmouth = 0.5 * (np.array(lmouth) + np.array(rmouth))
            midmouth[1] += hface * MASK_HEIGHT_FRAC_OF_FACE_DOWN
            half_wmouth = max(abs(lmouth[0] - midmouth[0]), wface * MASK_HALF_WIDTH_FRAC_OF_FACE)
            half_hmouth = max(abs(lmouth[1] - midmouth[1]), hface * MASK_HALF_HEIGHT_FRAC_OF_FACE)
            mouth = midmouth + np.array([[-half_wmouth, -half_hmouth], [half_wmouth, half_hmouth]])
            self.mouth_tracker.start_track(cv_image, mouth.reshape((4)))

        region = PolygonStamped()
        region.header = data.header
        region.polygon.points = [Point32(x=eye[0][0], y=eye[0][1], z=0),
                                 Point32(x=eye[1][0], y=eye[1][1], z=0)]
        self.eye_region_pub.publish(region)
        region.polygon.points = [Point32(x=mouth[0][0], y=mouth[0][1], z=0),
                                 Point32(x=mouth[1][0], y=mouth[1][1], z=0)]
        self.mask_region_pub.publish(region)

        # All overlays have colors below in case we use an RGB image in the future.
        for box in bboxes.astype(int):
            x, y, x2, y2 = box[0:4]
            # Draw a rectangle for each face bounding box.
            cv2.rectangle(cv_image, (x, y), (x2, y2), (0,0,255), 1)
        for face in landmarks.astype(int):
            for point in face:
                x, y = point
                # Draw a circle at each landmark.
                cv2.circle(cv_image, (x, y), 5, (0,0,255), 1)

        eye = eye.astype(int)
        cv2.rectangle(cv_image, tuple(eye[0].tolist()), tuple(eye[1].tolist()), (255,0,0), 2)
        mouth = mouth.astype(int)
        cv2.rectangle(cv_image, tuple(mouth[0].tolist()), tuple(mouth[1].tolist()), (255,0,0), 2)

        msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='passthrough')
        msg.header = data.header
        self.debug_image_pub.publish(msg)

    def clear_msmt_state(self):
        rospy.logwarn_throttle(1, '{}: Resetting'.format(self.name))
        self.eye_tracker.ok = False
        self.mouth_tracker.ok = False
        self.tlast = None
        self.tlast_detection = None

    def __init__(self, name):
        self.name = name

        self.enabled = True

        self.bridge = CvBridge()

        self.detector = insightface.model_zoo.get_model('retinaface_r50_v1')
        self.detector.prepare(ctx_id=-1, nms=0.4)

        self.mouth_tracker = ROITracker(CV_TRACKER_TYPE)
        self.eye_tracker = ROITracker(CV_TRACKER_TYPE)

        self.clear_msmt_state()

        self.eye_region_pub = rospy.Publisher(EYE_REGION_TOPIC, PolygonStamped, queue_size=10)
        self.mask_region_pub = rospy.Publisher(MASK_REGION_TOPIC, PolygonStamped, queue_size=10)

        self.debug_image_pub = rospy.Publisher(DEBUG_IMAGE_TOPIC, Image, queue_size=10)
        self.scaled_image_pub = rospy.Publisher(SCALED_IMAGE_TOPIC, Image, queue_size=10)

        self.tracking_status_pub = rospy.Publisher(TRACKING_STATUS_TOPIC, Bool, queue_size=10)

        self.image_sub = rospy.Subscriber(IMAGE_TOPIC, Image, self.image_callback, queue_size=1, buff_size=ROS_THERMAL_IMAGE_BUFFER_SIZE)

if __name__ == '__main__':
    rospy.init_node('ir_face_tracker')
    fdt = FaceDetectorTracker(rospy.get_name())

    def handle_enable(req):
        rospy.loginfo('Setting {} enabled to {}'.format(rospy.get_name(),
                                                        req.data))
        if not req.data:
            det_msg = Bool()
            det_msg.data = False
            fdt.tracking_status_pub.publish(det_msg)

        fdt.enabled = req.data
        return SetBoolResponse(True, '')

    s = rospy.Service(ENABLE_TOPIC, SetBool, handle_enable)
    rospy.spin()
